{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, email,re\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns; sns.set_style('whitegrid')\n",
    "import wordcloud\n",
    "\n",
    "# Network analysis\n",
    "import networkx as nx\n",
    "\n",
    "# NLP\n",
    "from nltk.tokenize.regexp import RegexpTokenizer\n",
    "\n",
    "from subprocess import check_output\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import string\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set display options to show all rows and columns\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(517401, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>allen-p/_sent_mail/1.</td>\n",
       "      <td>Message-ID: &lt;18782981.1075855378110.JavaMail.evans@thyme&gt;\\nDate: Mon, 14 May 2001 16:39:00 -0700 (PDT)\\nFrom: phillip.allen@enron.com\\nTo: tim.belden@enron.com\\nSubject: \\nMime-Version: 1.0\\nContent-Type: text/plain; charset=us-ascii\\nContent-Transfer-Encoding: 7bit\\nX-From: Phillip K Allen\\nX-To: Tim Belden &lt;Tim Belden/Enron@EnronXGate&gt;\\nX-cc: \\nX-bcc: \\nX-Folder: \\Phillip_Allen_Jan2002_1\\Allen, Phillip K.\\'Sent Mail\\nX-Origin: Allen-P\\nX-FileName: pallen (Non-Privileged).pst\\n\\nHere is our forecast\\n\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    file  \\\n",
       "0  allen-p/_sent_mail/1.   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          message  \n",
       "0  Message-ID: <18782981.1075855378110.JavaMail.evans@thyme>\\nDate: Mon, 14 May 2001 16:39:00 -0700 (PDT)\\nFrom: phillip.allen@enron.com\\nTo: tim.belden@enron.com\\nSubject: \\nMime-Version: 1.0\\nContent-Type: text/plain; charset=us-ascii\\nContent-Transfer-Encoding: 7bit\\nX-From: Phillip K Allen\\nX-To: Tim Belden <Tim Belden/Enron@EnronXGate>\\nX-cc: \\nX-bcc: \\nX-Folder: \\Phillip_Allen_Jan2002_1\\Allen, Phillip K.\\'Sent Mail\\nX-Origin: Allen-P\\nX-FileName: pallen (Non-Privileged).pst\\n\\nHere is our forecast\\n\\n   "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data into a DataFrame\n",
    "emails_df = pd.read_csv('emails.csv')\n",
    "print(emails_df.shape)\n",
    "emails_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Helper functions\n",
    "def get_text_from_email(msg):\n",
    "    '''To get the content from email objects'''\n",
    "    parts = []\n",
    "    for part in msg.walk():\n",
    "        if part.get_content_type() == 'text/plain':\n",
    "            parts.append( part.get_payload() )\n",
    "    return ''.join(parts)\n",
    "\n",
    "def split_email_addresses(line):\n",
    "    '''To separate multiple email addresses'''\n",
    "    if line:\n",
    "        addrs = line.split(',')\n",
    "        addrs = set(map(lambda x: x.strip(), addrs))\n",
    "    else:\n",
    "        addrs = set()\n",
    "    return addrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>Message-ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>From</th>\n",
       "      <th>To</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Mime-Version</th>\n",
       "      <th>Content-Type</th>\n",
       "      <th>Content-Transfer-Encoding</th>\n",
       "      <th>X-From</th>\n",
       "      <th>X-To</th>\n",
       "      <th>X-cc</th>\n",
       "      <th>X-bcc</th>\n",
       "      <th>X-Folder</th>\n",
       "      <th>X-Origin</th>\n",
       "      <th>X-FileName</th>\n",
       "      <th>content</th>\n",
       "      <th>user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>allen-p/_sent_mail/1.</td>\n",
       "      <td>&lt;18782981.1075855378110.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>Mon, 14 May 2001 16:39:00 -0700 (PDT)</td>\n",
       "      <td>{phillip.allen@enron.com}</td>\n",
       "      <td>{tim.belden@enron.com}</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td>text/plain; charset=us-ascii</td>\n",
       "      <td>7bit</td>\n",
       "      <td>Phillip K Allen</td>\n",
       "      <td>Tim Belden &lt;Tim Belden/Enron@EnronXGate&gt;</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>\\Phillip_Allen_Jan2002_1\\Allen, Phillip K.\\'Sent Mail</td>\n",
       "      <td>Allen-P</td>\n",
       "      <td>pallen (Non-Privileged).pst</td>\n",
       "      <td>Here is our forecast\\n\\n</td>\n",
       "      <td>allen-p</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    file                                     Message-ID  \\\n",
       "0  allen-p/_sent_mail/1.  <18782981.1075855378110.JavaMail.evans@thyme>   \n",
       "\n",
       "                                    Date                       From  \\\n",
       "0  Mon, 14 May 2001 16:39:00 -0700 (PDT)  {phillip.allen@enron.com}   \n",
       "\n",
       "                       To Subject Mime-Version                  Content-Type  \\\n",
       "0  {tim.belden@enron.com}                  1.0  text/plain; charset=us-ascii   \n",
       "\n",
       "  Content-Transfer-Encoding           X-From  \\\n",
       "0                      7bit  Phillip K Allen   \n",
       "\n",
       "                                       X-To X-cc X-bcc  \\\n",
       "0  Tim Belden <Tim Belden/Enron@EnronXGate>              \n",
       "\n",
       "                                                X-Folder X-Origin  \\\n",
       "0  \\Phillip_Allen_Jan2002_1\\Allen, Phillip K.\\'Sent Mail  Allen-P   \n",
       "\n",
       "                    X-FileName                    content     user  \n",
       "0  pallen (Non-Privileged).pst  Here is our forecast\\n\\n   allen-p  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parse the emails into a list email objects\n",
    "messages = list(map(email.message_from_string, emails_df['message']))\n",
    "emails_df.drop('message', axis=1, inplace=True)\n",
    "# Get fields from parsed email objects\n",
    "keys = messages[0].keys()\n",
    "for key in keys:\n",
    "    emails_df[key] = [doc[key] for doc in messages]\n",
    "# Parse content from emails\n",
    "emails_df['content'] = list(map(get_text_from_email, messages))\n",
    "# Split multiple email addresses\n",
    "emails_df['From'] = emails_df['From'].map(split_email_addresses)\n",
    "emails_df['To'] = emails_df['To'].map(split_email_addresses)\n",
    "\n",
    "# Extract the root of 'file' as 'user'\n",
    "emails_df['user'] = emails_df['file'].map(lambda x:x.split('/')[0])\n",
    "del messages\n",
    "\n",
    "emails_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2j/wrrdmx3j2b1ffnlrvvrzwgyr0000gn/T/ipykernel_12988/741351573.py:5: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  emails_df['Date'] = pd.to_datetime(emails_df['Date'], infer_datetime_format=True)\n",
      "/var/folders/2j/wrrdmx3j2b1ffnlrvvrzwgyr0000gn/T/ipykernel_12988/741351573.py:5: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  emails_df['Date'] = pd.to_datetime(emails_df['Date'], infer_datetime_format=True)\n",
      "/var/folders/2j/wrrdmx3j2b1ffnlrvvrzwgyr0000gn/T/ipykernel_12988/741351573.py:5: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise an error unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n",
      "  emails_df['Date'] = pd.to_datetime(emails_df['Date'], infer_datetime_format=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Date          object\n",
       "From          object\n",
       "To            object\n",
       "Subject       object\n",
       "X-From        object\n",
       "X-To          object\n",
       "X-cc          object\n",
       "X-bcc         object\n",
       "X-Folder      object\n",
       "X-Origin      object\n",
       "X-FileName    object\n",
       "content       object\n",
       "user          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set index and drop columns with two few values\n",
    "emails_df = emails_df.set_index('Message-ID')\\\n",
    "    .drop(['file', 'Mime-Version', 'Content-Type', 'Content-Transfer-Encoding'], axis=1)\n",
    "# Parse datetime\n",
    "emails_df['Date'] = pd.to_datetime(emails_df['Date'], infer_datetime_format=True)\n",
    "emails_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "emails_df=emails_df.sample(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to create the email network DataFrame...\n",
      "Processing emails...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing emails: 100%|██████████| 150/150 [00:00<00:00, 563.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing OpenAI analysis with multiprocessing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing emails:  14%|█▍        | 107/754 [00:43<03:21,  3.21it/s]"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import networkx as nx\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import os\n",
    "from sklearn.cluster import KMeans\n",
    "from email_analysis import analyze_emails_with_openai\n",
    "\n",
    "def sentence_tokenize(text):\n",
    "    return re.split(r'(?<=[.!?])\\s+', text)\n",
    "\n",
    "def normalize_text(text):\n",
    "    text = re.sub(r'[^a-zA-Z\\s.,!?]', '', text)\n",
    "    return text.lower()\n",
    "\n",
    "def textrank_summarize(text, num_sentences=5):\n",
    "    if not text or len(text.split()) < num_sentences:\n",
    "        return text\n",
    "\n",
    "    sentences = sentence_tokenize(text)\n",
    "    \n",
    "    if len(sentences) < 2:\n",
    "        return text\n",
    "\n",
    "    try:\n",
    "        tfidf = TfidfVectorizer().fit_transform(sentences)\n",
    "        similarity_matrix = cosine_similarity(tfidf)\n",
    "        graph = nx.from_numpy_array(similarity_matrix)\n",
    "        scores = nx.pagerank(graph)\n",
    "        ranked_sentences = sorted(((scores[i], s) for i, s in enumerate(sentences)), reverse=True)\n",
    "        summary = ' '.join(sent for _, sent in ranked_sentences[:num_sentences])\n",
    "        return summary\n",
    "    except ValueError:\n",
    "        return text\n",
    "\n",
    "def create_person_indexed_email_network_df(emails_df, max_features=1000, num_clusters=5, num_processes=4):\n",
    "    email_data = defaultdict(lambda: {'sent': [], 'received': []})\n",
    "    \n",
    "    print(\"Processing emails...\")\n",
    "    for _, row in tqdm(emails_df.iterrows(), total=len(emails_df), desc=\"Processing emails\"):\n",
    "        summarized_content = textrank_summarize(row['content'])\n",
    "        \n",
    "        email_info = {\n",
    "            'Date': row['Date'],\n",
    "            'From': list(row['From'])[0] if row['From'] else '',\n",
    "            'To': list(row['To'])[0] if row['To'] else '',\n",
    "            'Subject': row['Subject'],\n",
    "            'X-FileName': row['X-FileName'],\n",
    "            'content': summarized_content,\n",
    "        }\n",
    "        \n",
    "        for sender in row['From']:\n",
    "            email_data[sender]['sent'].append(email_info)\n",
    "        \n",
    "        for recipient in row['To']:\n",
    "            email_data[recipient]['received'].append(email_info)\n",
    "    \n",
    "    print(\"Performing OpenAI analysis with multiprocessing...\")\n",
    "    all_emails = [(person, [e['content'] for e in emails['sent'] + emails['received']]) \n",
    "                  for person, emails in email_data.items()]\n",
    "    \n",
    "    with ProcessPoolExecutor(max_workers=num_processes) as executor:\n",
    "        results = list(tqdm(executor.map(analyze_emails_with_openai, all_emails), \n",
    "                            total=len(all_emails), \n",
    "                            desc=\"Analyzing emails\"))\n",
    "    \n",
    "    openai_results = dict(results)\n",
    "    \n",
    "    print(\"Creating DataFrame structure...\")\n",
    "    data = []\n",
    "    all_summaries = []\n",
    "    for person, emails in tqdm(email_data.items(), desc=\"Processing people\"):\n",
    "        sent_df = pd.DataFrame(emails['sent'])\n",
    "        received_df = pd.DataFrame(emails['received'])\n",
    "        \n",
    "        openai_analysis = openai_results.get(person)\n",
    "        if openai_analysis:\n",
    "            topics, sentiment, emotion, people, organizations, locations, categories = openai_analysis\n",
    "        else:\n",
    "            topics, sentiment, emotion, people, organizations, locations, categories = [], \"Unknown\", \"Unknown\", [], [], [], {}\n",
    "        \n",
    "        if not sent_df.empty:\n",
    "            all_summaries.extend(sent_df['content'])\n",
    "        if not received_df.empty:\n",
    "            all_summaries.extend(received_df['content'])\n",
    "        \n",
    "        data.append({\n",
    "            'person': person,\n",
    "            'sent': sent_df,\n",
    "            'received': received_df,\n",
    "            'topics': topics,\n",
    "            'sentiment': sentiment,\n",
    "            'emotion': emotion,\n",
    "            'mentioned_people': people,\n",
    "            'mentioned_organizations': organizations,\n",
    "            'mentioned_locations': locations,\n",
    "            'email_categories': categories\n",
    "        })\n",
    "    \n",
    "    print(\"Performing TF-IDF transformation...\")\n",
    "    vectorizer = TfidfVectorizer(max_features=max_features)\n",
    "    with tqdm(total=1, desc=\"TF-IDF fit_transform\") as pbar:\n",
    "        tfidf_matrix = vectorizer.fit_transform(all_summaries)\n",
    "        pbar.update(1)\n",
    "    \n",
    "    print(\"Adding TF-IDF vectors to DataFrame...\")\n",
    "    summary_to_vector = dict(zip(all_summaries, tfidf_matrix.toarray()))\n",
    "    for entry in tqdm(data, desc=\"Adding TF-IDF vectors\"):\n",
    "        if not entry['sent'].empty:\n",
    "            entry['sent']['tfidf_vector'] = entry['sent']['content'].map(summary_to_vector)\n",
    "        if not entry['received'].empty:\n",
    "            entry['received']['tfidf_vector'] = entry['received']['content'].map(summary_to_vector)\n",
    "    \n",
    "    print(\"Clustering users...\")\n",
    "    user_vectors = []\n",
    "    for entry in data:\n",
    "        user_vector = np.zeros(max_features)\n",
    "        if not entry['sent'].empty:\n",
    "            user_vector += entry['sent']['tfidf_vector'].mean()\n",
    "        if not entry['received'].empty:\n",
    "            user_vector += entry['received']['tfidf_vector'].mean()\n",
    "        user_vectors.append(user_vector)\n",
    "    \n",
    "    kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "    clusters = kmeans.fit_predict(user_vectors)\n",
    "    \n",
    "    for i, entry in enumerate(data):\n",
    "        entry['cluster'] = clusters[i]\n",
    "    \n",
    "    print(\"Creating multi-index DataFrame...\")\n",
    "    email_network_df = pd.DataFrame(data).set_index('person')\n",
    "    \n",
    "    return email_network_df, vectorizer\n",
    "\n",
    "\n",
    "\n",
    "# Create the new DataFrame\n",
    "print(\"Starting to create the email network DataFrame...\")\n",
    "email_network_df, tfidf_vectorizer = create_person_indexed_email_network_df(emails_df, num_processes=os.cpu_count())\n",
    "\n",
    "# Display basic info about the DataFrame\n",
    "print(\"\\nDataFrame Info:\")\n",
    "print(email_network_df.info())\n",
    "\n",
    "# Display a sample of the DataFrame structure\n",
    "print(\"\\nSample of the DataFrame structure:\")\n",
    "sample_person = email_network_df.index[0]  # Get the first person in the DataFrame\n",
    "print(f\"\\nData for {sample_person}:\")\n",
    "print(\"\\nSent emails:\")\n",
    "print(email_network_df.loc[sample_person, 'sent'].head())\n",
    "print(\"\\nReceived emails:\")\n",
    "print(email_network_df.loc[sample_person, 'received'].head())\n",
    "print(\"\\nTopics:\", email_network_df.loc[sample_person, 'topics'])\n",
    "print(\"Sentiment:\", email_network_df.loc[sample_person, 'sentiment'])\n",
    "print(\"Emotion:\", email_network_df.loc[sample_person, 'emotion'])\n",
    "print(\"Mentioned People:\", email_network_df.loc[sample_person, 'mentioned_people'])\n",
    "print(\"Mentioned Organizations:\", email_network_df.loc[sample_person, 'mentioned_organizations'])\n",
    "print(\"Mentioned Locations:\", email_network_df.loc[sample_person, 'mentioned_locations'])\n",
    "print(\"Email Categories:\", email_network_df.loc[sample_person, 'email_categories'])\n",
    "print(\"Cluster:\", email_network_df.loc[sample_person, 'cluster'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique organizations mentioned:\n",
      "- (No additional organizations mentioned)\n",
      "- (No organizations mentioned)\n",
      "- (No other organizations mentioned)\n",
      "- (No other organizations were specified in the content)\n",
      "- (None other mentioned)\n",
      "- (no other organizations mentioned)\n",
      "- AEP\n",
      "- AEP (American Electric Power)\n",
      "- Anadarko\n",
      "- Andrews & Kurth L.L.P.\n",
      "- Assembly\n",
      "- Calpine Canada Natural Gas Partnership\n",
      "- Conoco\n",
      "- Corp\n",
      "- DandyDon\n",
      "- Direct Access Coalition\n",
      "- Dynegy\n",
      "- EES\n",
      "- EES (Energy Services)\n",
      "- EIA\n",
      "- EP Energy\n",
      "- EPEnergy\n",
      "- Eaton and Cottrell\n",
      "- El Paso Merchant Energy\n",
      "- Energy Commission\n",
      "- Enron\n",
      "- Enron (implied)\n",
      "- Enron Europe Limited\n",
      "- Enron Metals\n",
      "- Enron North America\n",
      "- EnronOnline\n",
      "- Entergy\n",
      "- Exxon\n",
      "- FERC\n",
      "- Fox News\n",
      "- Fulbright\n",
      "- Global Government Affairs\n",
      "- Global Products\n",
      "- HPL\n",
      "- IC\n",
      "- ISO\n",
      "- Independent Energy Producers\n",
      "- Independent Energy Producers (as an organization)\n",
      "- Jones Day\n",
      "- Kaye Scholer LLP\n",
      "- LGEN (LAGN)\n",
      "- LGEN (LGEN unit presumably related to AEP)\n",
      "- LPSC\n",
      "- LS\n",
      "- LSU (Louisiana State University)\n",
      "- MSN\n",
      "- Marathon Oil\n",
      "- Mayer Brown\n",
      "- McNally Temple Associates, Inc.\n",
      "- MichCon\n",
      "- Michigan Consolidated Gas Company\n",
      "- Millennium Biltmore Hotel\n",
      "- Mobil Oil Corporation\n",
      "- N/A\n",
      "- N/A (There are no other organizations mentioned)\n",
      "- N/A (no additional organizations mentioned)\n",
      "- NERC\n",
      "- None explicitly mentioned\n",
      "- None identified\n",
      "- None mentioned\n",
      "- None specified\n",
      "- Nonprofits\n",
      "- Not applicable\n",
      "- Not applicable (no additional organizations mentioned)\n",
      "- Not applicable (no other organizations mentioned)\n",
      "- Not applicable (no other specific organizations mentioned)\n",
      "- Not enough relevant organizations mentioned.\n",
      "- Not mentioned in the content (only one organization besides sender's)\n",
      "- Not specifically mentioned\n",
      "- Not specified\n",
      "- Not specified in the content\n",
      "- Not specified in the email content\n",
      "- Pacific Gas and Electric (PG&E)\n",
      "- Questia\n",
      "- Questia Media\n",
      "- RTO\n",
      "- Reliant Energy\n",
      "- Rigzone\n",
      "- Southern California Edison\n",
      "- TDC Energy\n",
      "- TVA\n",
      "- TVA (Tennessee Valley Authority)\n",
      "- Teco\n",
      "- Tiemann Law\n",
      "- West Trading\n",
      "- Whammy Web\n",
      "- Williams Energy Marketing & Trade Co.\n",
      "- [N/A]\n",
      "- [No other organizations mentioned]\n",
      "\n",
      "Unique locations mentioned:\n",
      "- (No locations mentioned)\n",
      "- (No specific locations mentioned aside from general locality)\n",
      "- (No specific locations mentioned)\n",
      "- (None mentioned)\n",
      "- (None other mentioned)\n",
      "- (no specific locations mentioned)\n",
      "- 88 Wood Street\n",
      "- California\n",
      "- Dallas, Texas\n",
      "- Data room\n",
      "- Germany\n",
      "- Heinsbergen Room\n",
      "- Houston\n",
      "- Houston (implied from the phone area code)\n",
      "- London\n",
      "- Los Angeles\n",
      "- Louisiana\n",
      "- MDEA\n",
      "- MDEA (Midwest Electric Delivery Area)\n",
      "- Michigan\n",
      "- Michigan (implied by Michigan Consolidated Gas Company)\n",
      "- Millennium Biltmore Hotel\n",
      "- N/A\n",
      "- N/A (There are no specific locations mentioned)\n",
      "- N/A (no locations mentioned)\n",
      "- N/A (no specific locations mentioned)\n",
      "- N/A (specific locations are not mentioned in the email content)\n",
      "- None identified\n",
      "- None mentioned\n",
      "- None specified\n",
      "- North America\n",
      "- Not applicable\n",
      "- Not applicable (no locations mentioned)\n",
      "- Not applicable (no other locations mentioned)\n",
      "- Not applicable (no specific locations mentioned)\n",
      "- Not enough information to specify locations\n",
      "- Not enough mentions to list locations.\n",
      "- Not enough relevant locations mentioned\n",
      "- Not enough relevant locations mentioned.\n",
      "- Not explicitly mentioned\n",
      "- Not mentioned\n",
      "- Not mentioned in the content (only one location)\n",
      "- Not specified\n",
      "- Not specified in the content\n",
      "- Not specified in the email content\n",
      "- Portland\n",
      "- Rockies\n",
      "- Sacramento\n",
      "- TVA border\n",
      "- UK\n",
      "- [N/A]\n",
      "- [No specific locations mentioned]\n"
     ]
    }
   ],
   "source": [
    "# For mentioned_organizations\n",
    "org_set = set()\n",
    "for orgs in email_network_df['mentioned_organizations']:\n",
    "    org_set.update(orgs)\n",
    "\n",
    "print(\"Unique organizations mentioned:\")\n",
    "for org in sorted(org_set):\n",
    "    print(f\"- {org}\")\n",
    "\n",
    "# For mentioned_locations\n",
    "loc_set = set()\n",
    "for locs in email_network_df['mentioned_locations']:\n",
    "    loc_set.update(locs)\n",
    "\n",
    "print(\"\\nUnique locations mentioned:\")\n",
    "for loc in sorted(loc_set):\n",
    "    print(f\"- {loc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "def clean_subject(subject):\n",
    "    return re.sub(r'^(Re:|Fwd:)\\s*', '', subject, flags=re.IGNORECASE).strip()\n",
    "\n",
    "def summarize_threads(emails_df):\n",
    "    threads = defaultdict(list)\n",
    "    \n",
    "    for _, email in emails_df.iterrows():\n",
    "        clean_subj = clean_subject(email['Subject'])\n",
    "        threads[clean_subj].append(email['content'])\n",
    "    \n",
    "    summaries = {}\n",
    "    for subject, contents in threads.items():\n",
    "        full_thread = \" \".join(contents)\n",
    "        summaries[subject] = textrank_summarize(full_thread)\n",
    "    \n",
    "    return summaries\n",
    "\n",
    "def add_thread_summaries(email_network_df):\n",
    "    email_network_df['thread_summaries'] = email_network_df.apply(\n",
    "        lambda row: summarize_threads(pd.concat([row['sent'], row['received']])),\n",
    "        axis=1\n",
    "    )\n",
    "    return email_network_df\n",
    "\n",
    "# Apply the function to your DataFrame\n",
    "email_network_df = add_thread_summaries(email_network_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Credit Watch List--Week of 11/5/01': \"If there are any personnel in your group that were not included in this distribution, please insure that they receive a copy of this report. To add additional people to this distribution, or if this report has been sent to you in error, please contact Veronica Espinoza at x6-6002. Attached is a revised Credit Watch listing for the week of 11/05/01. For other questions, please contact Jason R. There are no updates from last week's list.\"}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email_network_df.thread_summaries.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent</th>\n",
       "      <th>received</th>\n",
       "      <th>topics</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>emotion</th>\n",
       "      <th>mentioned_people</th>\n",
       "      <th>mentioned_organizations</th>\n",
       "      <th>mentioned_locations</th>\n",
       "      <th>email_categories</th>\n",
       "      <th>cluster</th>\n",
       "      <th>thread_summaries</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>michael.etringer@enron.com</th>\n",
       "      <td>Empty DataFrame\n",
       "Columns: []\n",
       "Index: []</td>\n",
       "      <td>Date                         From  \\\n",
       "0  2001-11-05 08:48:47-08:00  veronica.espinoza@enron.com   \n",
       "1  2001-02-08 03:32:00-08:00         susan.mara@enron.com   \n",
       "2  2001-06-14 04:54:00-07:00         susan.mara@enron.com   \n",
       "\n",
       "                         To  \\\n",
       "0      k..ratnala@enron.com   \n",
       "1  brenda.barreda@enron.com   \n",
       "2  brenda.barreda@enron.com   \n",
       "\n",
       "                                                                                                  Subject  \\\n",
       "0                                                                      Credit Watch List--Week of 11/5/01   \n",
       "1                                                                                  AReM: Hertzberg Update   \n",
       "2  FYI: Sacramento Bee--Dan Walters: Repaying huge power debts still\\n\\t looms as a high political hurdle   \n",
       "\n",
       "                    X-FileName  \\\n",
       "0  GNEMEC (Non-Privileged).pst   \n",
       "1                    skean.nsf   \n",
       "2                 jdasovic.nsf   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              content  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             To add additional people to this distribution, or if this report has been sent to you in error, please contact Veronica Espinoza at x6-6002. If there are any personnel in your group that were not included in this distribution, please insure that they receive a copy of this report. Attached is a revised Credit Watch listing for the week of 11/05/01. For other questions, please contact Jason R. There are no updates from last week's list.   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                 Provide $150 million to develop clean and efficient renewable energy supply \\n\\nAllow plants up to 100 megawatts to be cityby local government andnot\\nthrough Energy Commission review \\n\\nEnsure power by requiring new power plants to enter into purchasing\\nagreements with the state. They also introduced five bills to provide funding to\" \\n\\nReplace energy inefficient appliances like refrigerators and air\\nconditioners; \\nGive schools grants and loans to decrease consumption \\nProvide 50 percent grants and 50 percent loans to local governments to\\nretrofit buildings; \\nEstablish a Mobile Efficiency Brigade with $100 million in grants to\\nnonprofits to hire a team of people to distribute low-energy lightbulbs to\\nresidences, saving 125 megawatts, but help other conservation programs get\\nstarted twell before the summer by providig people to do the work while\\nlearning new skills. 9:30 a.m., SACRAMENTO _ Assembly Speaker Robert Hertzberg and others\\ndiscuss legislation to promote energy conservation and increase power\\nsupplies, Capitol, room 317. Said the energy efficiency package may save as many as 500 megawatts,\\nequivalent to a new power plant. Contact: 916-445-4571.   \n",
       "2  A dizzying array of MOU alternatives\\nis being floated, including an effort by Burton and Assembly Speaker Bob\\nHertzberg to persuade Edison creditors to write off part of the debt, and\\nfor big industrial and power consumers to shoulder the rest in return for\\nrecapturing the authority to make power supply deals outside the utility\\ngrid. PG&amp;E already\\nhas declared bankruptcy, and Edison was on the verge when Davis hurriedly\\nsigned a \"memorandum of understanding\" (MOU) on a rescue scheme, the\\ncenterpieces being state purchase of Edison's share of the intercity power\\ngrid, plus a plan for ratepayers to pay off the utility's debts. And then there are the $14 billion or so in debts that the state's two big\\nutilities, Pacific Gas and Electric and Southern California Edison, incurred\\nfor power purchases before their credit was cut off in January. \"On an issue like this, they (legislators) ought to be able to vote their\\nconsciences,\" Burton told reporters, denouncing the Edison deal as a\\n\"flat-ass bailout.\" \\nDavis spokesman Steve Maviglio rejected Burton's account: \"The governor's\\ntoo smart to do any of that.\" \\nAs the public squabbling heats up, so is the private search for a compromise\\nthat Edison, consumerists and other principal players can accept -- without\\nmuch confidence that it can be found. Despite the\\nrecent drop in spot power prices, however, many aspects of the energy crisis\\nremain unresolved, and chief among them is liquidating the $20 billion-plus\\nin debts that utilities and the state have accumulated for power purchases.   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               tfidf_vector  \n",
       "0                                                                                 [0.0, 0.0, 0.11076183030737578, 0.0, 0.0, 0.0, 0.11582547486682462, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10546876001425726, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]  \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13110841261755446, 0.0, 0.0, 0.0, 0.0, 0.06638950994636103, 0.0, 0.0, 0.066050667339742, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.048147376595979265, 0.0, 0.06638950994636103, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06011327671628271, 0.0, 0.06638950994636103, 0.0, 0.0, 0.0, 0.0, 0.11635810909787088, ...]  \n",
       "2                                                                                                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.051623377365471214, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04131318835149119, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]</td>\n",
       "      <td>[- Distribution of reports, - Renewable energy funding, - Power plant regulations, - Energy conservation initiatives, - Legislation discussions, - Grant and loan programs for energy efficiency, - Role of local governments in energy projects, - Updates on energy efficiency bills, - Collaboration with nonprofits for energy conservation, - Bankruptcy of PG&amp;E and Edison]</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Informative</td>\n",
       "      <td>[Veronica Espinoza, Jason R., Robert Hertzberg, Burton, Bob Hertzberg]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'Work-related': '80%', 'Personal': '0%', 'Urgent': '0%', 'Informational': '20%', 'Action Required': '0%', 'Follow-up': '0%', 'Other': '0%'}</td>\n",
       "      <td>3</td>\n",
       "      <td>{'Credit Watch List--Week of 11/5/01': 'If there are any personnel in your group that were not included in this distribution, please insure that they receive a copy of this report. To add additional people to this distribution, or if this report has been sent to you in error, please contact Veronica Espinoza at x6-6002. Attached is a revised Credit Watch listing for the week of 11/05/01. For other questions, please contact Jason R. There are no updates from last week's list.', 'AReM: Hertzberg Update': 'Provide $150 million to develop clean and efficient renewable energy supply \n",
       "\n",
       "Allow plants up to 100 megawatts to be cityby local government andnot\n",
       "through Energy Commission review \n",
       "\n",
       "Ensure power by requiring new power plants to enter into purchasing\n",
       "agreements with the state. They also introduced five bills to provide funding to\" \n",
       "\n",
       "Replace energy inefficient appliances like refrigerators and air\n",
       "conditioners; \n",
       "Give schools grants and loans to decrease consumption \n",
       "Provide 50 percent grants and 50 percent loans to local governments to\n",
       "retrofit buildings; \n",
       "Establish a Mobile Efficiency Brigade with $100 million in grants to\n",
       "nonprofits to hire a team of people to distribute low-energy lightbulbs to\n",
       "residences, saving 125 megawatts, but help other conservation programs get\n",
       "started twell before the summer by providig people to do the work while\n",
       "learning new skills. Contact: 916-445-4571. Said the energy efficiency package may save as many as 500 megawatts,\n",
       "equivalent to a new power plant. 9:30 a.m., SACRAMENTO _ Assembly Speaker Robert Hertzberg and others\n",
       "discuss legislation to promote energy conservation and increase power\n",
       "supplies, Capitol, room 317.', 'FYI: Sacramento Bee--Dan Walters: Repaying huge power debts still\n",
       "\t looms as a high political hurdle': 'A dizzying array of MOU alternatives\n",
       "is being floated, including an effort by Burton and Assembly Speaker Bob\n",
       "Hertzberg to persuade Edison creditors to write off part of the debt, and\n",
       "for big industrial and power consumers to shoulder the rest in return for\n",
       "recapturing the authority to make power supply deals outside the utility\n",
       "grid. Despite the\n",
       "recent drop in spot power prices, however, many aspects of the energy crisis\n",
       "remain unresolved, and chief among them is liquidating the $20 billion-plus\n",
       "in debts that utilities and the state have accumulated for power purchases. PG&amp;E already\n",
       "has declared bankruptcy, and Edison was on the verge when Davis hurriedly\n",
       "signed a \"memorandum of understanding\" (MOU) on a rescue scheme, the\n",
       "centerpieces being state purchase of Edison's share of the intercity power\n",
       "grid, plus a plan for ratepayers to pay off the utility's debts. And then there are the $14 billion or so in debts that the state's two big\n",
       "utilities, Pacific Gas and Electric and Southern California Edison, incurred\n",
       "for power purchases before their credit was cut off in January. \"On an issue like this, they (legislators) ought to be able to vote their\n",
       "consciences,\" Burton told reporters, denouncing the Edison deal as a\n",
       "\"flat-ass bailout.\" \n",
       "Davis spokesman Steve Maviglio rejected Burton's account: \"The governor's\n",
       "too smart to do any of that.\" \n",
       "As the public squabbling heats up, so is the private search for a compromise\n",
       "that Edison, consumerists and other principal players can accept -- without\n",
       "much confidence that it can be found.'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             sent  \\\n",
       "person                                                              \n",
       "michael.etringer@enron.com  Empty DataFrame\n",
       "Columns: []\n",
       "Index: []   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                received  \\\n",
       "person                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
       "michael.etringer@enron.com                          Date                         From  \\\n",
       "0  2001-11-05 08:48:47-08:00  veronica.espinoza@enron.com   \n",
       "1  2001-02-08 03:32:00-08:00         susan.mara@enron.com   \n",
       "2  2001-06-14 04:54:00-07:00         susan.mara@enron.com   \n",
       "\n",
       "                         To  \\\n",
       "0      k..ratnala@enron.com   \n",
       "1  brenda.barreda@enron.com   \n",
       "2  brenda.barreda@enron.com   \n",
       "\n",
       "                                                                                                  Subject  \\\n",
       "0                                                                      Credit Watch List--Week of 11/5/01   \n",
       "1                                                                                  AReM: Hertzberg Update   \n",
       "2  FYI: Sacramento Bee--Dan Walters: Repaying huge power debts still\\n\\t looms as a high political hurdle   \n",
       "\n",
       "                    X-FileName  \\\n",
       "0  GNEMEC (Non-Privileged).pst   \n",
       "1                    skean.nsf   \n",
       "2                 jdasovic.nsf   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              content  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             To add additional people to this distribution, or if this report has been sent to you in error, please contact Veronica Espinoza at x6-6002. If there are any personnel in your group that were not included in this distribution, please insure that they receive a copy of this report. Attached is a revised Credit Watch listing for the week of 11/05/01. For other questions, please contact Jason R. There are no updates from last week's list.   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                 Provide $150 million to develop clean and efficient renewable energy supply \\n\\nAllow plants up to 100 megawatts to be cityby local government andnot\\nthrough Energy Commission review \\n\\nEnsure power by requiring new power plants to enter into purchasing\\nagreements with the state. They also introduced five bills to provide funding to\" \\n\\nReplace energy inefficient appliances like refrigerators and air\\nconditioners; \\nGive schools grants and loans to decrease consumption \\nProvide 50 percent grants and 50 percent loans to local governments to\\nretrofit buildings; \\nEstablish a Mobile Efficiency Brigade with $100 million in grants to\\nnonprofits to hire a team of people to distribute low-energy lightbulbs to\\nresidences, saving 125 megawatts, but help other conservation programs get\\nstarted twell before the summer by providig people to do the work while\\nlearning new skills. 9:30 a.m., SACRAMENTO _ Assembly Speaker Robert Hertzberg and others\\ndiscuss legislation to promote energy conservation and increase power\\nsupplies, Capitol, room 317. Said the energy efficiency package may save as many as 500 megawatts,\\nequivalent to a new power plant. Contact: 916-445-4571.   \n",
       "2  A dizzying array of MOU alternatives\\nis being floated, including an effort by Burton and Assembly Speaker Bob\\nHertzberg to persuade Edison creditors to write off part of the debt, and\\nfor big industrial and power consumers to shoulder the rest in return for\\nrecapturing the authority to make power supply deals outside the utility\\ngrid. PG&E already\\nhas declared bankruptcy, and Edison was on the verge when Davis hurriedly\\nsigned a \"memorandum of understanding\" (MOU) on a rescue scheme, the\\ncenterpieces being state purchase of Edison's share of the intercity power\\ngrid, plus a plan for ratepayers to pay off the utility's debts. And then there are the $14 billion or so in debts that the state's two big\\nutilities, Pacific Gas and Electric and Southern California Edison, incurred\\nfor power purchases before their credit was cut off in January. \"On an issue like this, they (legislators) ought to be able to vote their\\nconsciences,\" Burton told reporters, denouncing the Edison deal as a\\n\"flat-ass bailout.\" \\nDavis spokesman Steve Maviglio rejected Burton's account: \"The governor's\\ntoo smart to do any of that.\" \\nAs the public squabbling heats up, so is the private search for a compromise\\nthat Edison, consumerists and other principal players can accept -- without\\nmuch confidence that it can be found. Despite the\\nrecent drop in spot power prices, however, many aspects of the energy crisis\\nremain unresolved, and chief among them is liquidating the $20 billion-plus\\nin debts that utilities and the state have accumulated for power purchases.   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               tfidf_vector  \n",
       "0                                                                                 [0.0, 0.0, 0.11076183030737578, 0.0, 0.0, 0.0, 0.11582547486682462, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10546876001425726, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]  \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13110841261755446, 0.0, 0.0, 0.0, 0.0, 0.06638950994636103, 0.0, 0.0, 0.066050667339742, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.048147376595979265, 0.0, 0.06638950994636103, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06011327671628271, 0.0, 0.06638950994636103, 0.0, 0.0, 0.0, 0.0, 0.11635810909787088, ...]  \n",
       "2                                                                                                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.051623377365471214, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04131318835149119, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]     \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                       topics  \\\n",
       "person                                                                                                                                                                                                                                                                                                                                                                                                          \n",
       "michael.etringer@enron.com  [- Distribution of reports, - Renewable energy funding, - Power plant regulations, - Energy conservation initiatives, - Legislation discussions, - Grant and loan programs for energy efficiency, - Role of local governments in energy projects, - Updates on energy efficiency bills, - Collaboration with nonprofits for energy conservation, - Bankruptcy of PG&E and Edison]   \n",
       "\n",
       "                           sentiment      emotion  \\\n",
       "person                                              \n",
       "michael.etringer@enron.com   Neutral  Informative   \n",
       "\n",
       "                                                                                  mentioned_people  \\\n",
       "person                                                                                               \n",
       "michael.etringer@enron.com  [Veronica Espinoza, Jason R., Robert Hertzberg, Burton, Bob Hertzberg]   \n",
       "\n",
       "                           mentioned_organizations mentioned_locations  \\\n",
       "person                                                                   \n",
       "michael.etringer@enron.com                      []                  []   \n",
       "\n",
       "                                                                                                                                                        email_categories  \\\n",
       "person                                                                                                                                                                     \n",
       "michael.etringer@enron.com  {'Work-related': '80%', 'Personal': '0%', 'Urgent': '0%', 'Informational': '20%', 'Action Required': '0%', 'Follow-up': '0%', 'Other': '0%'}   \n",
       "\n",
       "                            cluster  \\\n",
       "person                                \n",
       "michael.etringer@enron.com        3   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   thread_summaries  \n",
       "person                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
       "michael.etringer@enron.com  {'Credit Watch List--Week of 11/5/01': 'If there are any personnel in your group that were not included in this distribution, please insure that they receive a copy of this report. To add additional people to this distribution, or if this report has been sent to you in error, please contact Veronica Espinoza at x6-6002. Attached is a revised Credit Watch listing for the week of 11/05/01. For other questions, please contact Jason R. There are no updates from last week's list.', 'AReM: Hertzberg Update': 'Provide $150 million to develop clean and efficient renewable energy supply \n",
       "\n",
       "Allow plants up to 100 megawatts to be cityby local government andnot\n",
       "through Energy Commission review \n",
       "\n",
       "Ensure power by requiring new power plants to enter into purchasing\n",
       "agreements with the state. They also introduced five bills to provide funding to\" \n",
       "\n",
       "Replace energy inefficient appliances like refrigerators and air\n",
       "conditioners; \n",
       "Give schools grants and loans to decrease consumption \n",
       "Provide 50 percent grants and 50 percent loans to local governments to\n",
       "retrofit buildings; \n",
       "Establish a Mobile Efficiency Brigade with $100 million in grants to\n",
       "nonprofits to hire a team of people to distribute low-energy lightbulbs to\n",
       "residences, saving 125 megawatts, but help other conservation programs get\n",
       "started twell before the summer by providig people to do the work while\n",
       "learning new skills. Contact: 916-445-4571. Said the energy efficiency package may save as many as 500 megawatts,\n",
       "equivalent to a new power plant. 9:30 a.m., SACRAMENTO _ Assembly Speaker Robert Hertzberg and others\n",
       "discuss legislation to promote energy conservation and increase power\n",
       "supplies, Capitol, room 317.', 'FYI: Sacramento Bee--Dan Walters: Repaying huge power debts still\n",
       "\t looms as a high political hurdle': 'A dizzying array of MOU alternatives\n",
       "is being floated, including an effort by Burton and Assembly Speaker Bob\n",
       "Hertzberg to persuade Edison creditors to write off part of the debt, and\n",
       "for big industrial and power consumers to shoulder the rest in return for\n",
       "recapturing the authority to make power supply deals outside the utility\n",
       "grid. Despite the\n",
       "recent drop in spot power prices, however, many aspects of the energy crisis\n",
       "remain unresolved, and chief among them is liquidating the $20 billion-plus\n",
       "in debts that utilities and the state have accumulated for power purchases. PG&E already\n",
       "has declared bankruptcy, and Edison was on the verge when Davis hurriedly\n",
       "signed a \"memorandum of understanding\" (MOU) on a rescue scheme, the\n",
       "centerpieces being state purchase of Edison's share of the intercity power\n",
       "grid, plus a plan for ratepayers to pay off the utility's debts. And then there are the $14 billion or so in debts that the state's two big\n",
       "utilities, Pacific Gas and Electric and Southern California Edison, incurred\n",
       "for power purchases before their credit was cut off in January. \"On an issue like this, they (legislators) ought to be able to vote their\n",
       "consciences,\" Burton told reporters, denouncing the Edison deal as a\n",
       "\"flat-ass bailout.\" \n",
       "Davis spokesman Steve Maviglio rejected Burton's account: \"The governor's\n",
       "too smart to do any of that.\" \n",
       "As the public squabbling heats up, so is the private search for a compromise\n",
       "that Edison, consumerists and other principal players can accept -- without\n",
       "much confidence that it can be found.'}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "display(email_network_df.iloc[[100]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Email volume\n",
    "email_network_df['sent_count'] = email_network_df['sent'].apply(lambda x: len(x) if isinstance(x, pd.DataFrame) else 0)\n",
    "email_network_df['received_count'] = email_network_df['received'].apply(lambda x: len(x) if isinstance(x, pd.DataFrame) else 0)\n",
    "email_network_df['total_volume'] = email_network_df['sent_count'] + email_network_df['received_count']\n",
    "\n",
    "# Response rate\n",
    "#email_network_df['response_rate'] = email_network_df.apply(lambda row: calculate_response_rate(row['sent'], row['received']), axis=1)\n",
    "\n",
    "# Thread depth (approximation based on 'Re:' count in subject)\n",
    "def calculate_thread_depth(sent, received):\n",
    "    all_emails = pd.concat([sent, received]) if isinstance(sent, pd.DataFrame) and isinstance(received, pd.DataFrame) else pd.DataFrame()\n",
    "    if len(all_emails) > 0:\n",
    "        return all_emails['Subject'].str.count('Re:').mean()\n",
    "    return 0\n",
    "\n",
    "email_network_df['avg_thread_depth'] = email_network_df.apply(lambda row: calculate_thread_depth(row['sent'], row['received']), axis=1)\n",
    "\n",
    "def count_unique_contacts(sent, received):\n",
    "    contacts = set()\n",
    "    if isinstance(sent, pd.DataFrame):\n",
    "        # Check for 'To' or alternative columns that might contain recipient information\n",
    "        recipient_columns = ['To', 'X-To', 'Recipients', 'Recipient']\n",
    "        for col in recipient_columns:\n",
    "            if col in sent.columns:\n",
    "                contacts.update(sent[col].dropna())\n",
    "                break\n",
    "    if isinstance(received, pd.DataFrame):\n",
    "        # Check for 'From' or alternative columns that might contain sender information\n",
    "        sender_columns = ['From', 'X-From', 'Sender']\n",
    "        for col in sender_columns:\n",
    "            if col in received.columns:\n",
    "                contacts.update(received[col].dropna())\n",
    "                break\n",
    "    return len(contacts)\n",
    "\n",
    "email_network_df['unique_contacts'] = email_network_df.apply(lambda row: count_unique_contacts(row['sent'], row['received']), axis=1)\n",
    "\n",
    "def calculate_response_rate(sent, received):\n",
    "    if isinstance(received, pd.DataFrame) and len(received) > 0:\n",
    "        if isinstance(sent, pd.DataFrame) and len(sent) > 0:\n",
    "            replies = sent[sent['Subject'].str.startswith('Re:', na=False)]\n",
    "            return len(replies) / len(received)\n",
    "    return 0\n",
    "\n",
    "email_network_df['response_rate'] = email_network_df.apply(lambda row: calculate_response_rate(row['sent'], row['received']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "def create_email_network(email_network_df):\n",
    "    G = nx.DiGraph()\n",
    "    for person, row in email_network_df.iterrows():\n",
    "        if isinstance(row['sent'], pd.DataFrame):\n",
    "            for _, email in row['sent'].iterrows():\n",
    "                recipients = email['To'].split(';') if isinstance(email['To'], str) else [email['To']]\n",
    "                for recipient in recipients:\n",
    "                    G.add_edge(person, recipient.strip())\n",
    "    return G\n",
    "\n",
    "def calculate_network_features(email_network_df):\n",
    "    G = create_email_network(email_network_df)\n",
    "    \n",
    "    # 1. Centrality measures\n",
    "    degree_centrality = nx.degree_centrality(G)\n",
    "    betweenness_centrality = nx.betweenness_centrality(G)\n",
    "    eigenvector_centrality = nx.eigenvector_centrality(G, max_iter=1000)\n",
    "    \n",
    "    # 2. Community detection using Girvan-Newman algorithm\n",
    "    communities_generator = nx.community.girvan_newman(G.to_undirected())\n",
    "    top_level_communities = next(communities_generator)\n",
    "    community_dict = {node: i for i, community in enumerate(top_level_communities) for node in community}\n",
    "    \n",
    "    # 3. Influence score\n",
    "    pagerank = nx.pagerank(G)\n",
    "    \n",
    "    # Add these features to the DataFrame\n",
    "    email_network_df['degree_centrality'] = email_network_df.index.map(degree_centrality)\n",
    "    email_network_df['betweenness_centrality'] = email_network_df.index.map(betweenness_centrality)\n",
    "    email_network_df['eigenvector_centrality'] = email_network_df.index.map(eigenvector_centrality)\n",
    "    email_network_df['community'] = email_network_df.index.map(community_dict)\n",
    "    email_network_df['influence_score'] = email_network_df.index.map(pagerank)\n",
    "    \n",
    "    return email_network_df\n",
    "\n",
    "# Calculate forwarded and replied email counts\n",
    "def calculate_email_interaction_counts(email_network_df):\n",
    "    def count_interactions(sent, received):\n",
    "        forwarded_count = 0\n",
    "        replied_count = 0\n",
    "        if isinstance(sent, pd.DataFrame) and 'Subject' in sent.columns:\n",
    "            forwarded_count = sent['Subject'].str.contains('Fwd:', case=False, na=False).sum()\n",
    "        if isinstance(received, pd.DataFrame) and 'Subject' in received.columns:\n",
    "            replied_count = received['Subject'].str.contains('Re:', case=False, na=False).sum()\n",
    "        return pd.Series({'forwarded_count': forwarded_count, 'replied_count': replied_count})\n",
    "\n",
    "    interaction_counts = email_network_df.apply(lambda row: count_interactions(row['sent'], row['received']), axis=1)\n",
    "    return pd.concat([email_network_df, interaction_counts], axis=1)\n",
    "\n",
    "\n",
    "# Apply the functions\n",
    "email_network_df = calculate_email_interaction_counts(email_network_df)\n",
    "email_network_df = calculate_network_features(email_network_df)\n",
    "\n",
    "# Adjust influence score based on forwarded and replied counts\n",
    "email_network_df['adjusted_influence_score'] = email_network_df['influence_score'] * (1 + email_network_df['forwarded_count'] + email_network_df['replied_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values with appropriate defaults\n",
    "email_network_df = email_network_df.fillna({\n",
    "    'degree_centrality': 0,\n",
    "    'betweenness_centrality': 0,\n",
    "    'eigenvector_centrality': 0,\n",
    "    'community': -1,\n",
    "    'influence_score': 0,\n",
    "    'adjusted_influence_score': 0\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##TODO: FIX THIS IT DOES NOT WORK\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def create_email_network(email_network_df):\n",
    "    G = nx.DiGraph()\n",
    "    for person, row in email_network_df.iterrows():\n",
    "        if isinstance(row['sent'], pd.DataFrame):\n",
    "            for _, email in row['sent'].iterrows():\n",
    "                if 'To' in email:\n",
    "                    recipients = email['To'].split(';') if isinstance(email['To'], str) else [email['To']]\n",
    "                    for recipient in recipients:\n",
    "                        if isinstance(recipient, str):\n",
    "                            G.add_edge(person, recipient.strip())\n",
    "    return G\n",
    "\n",
    "def calculate_network_features(email_network_df):\n",
    "    G = create_email_network(email_network_df)\n",
    "    \n",
    "    # 1. Centrality measures\n",
    "    degree_centrality = nx.degree_centrality(G)\n",
    "    betweenness_centrality = nx.betweenness_centrality(G)\n",
    "    eigenvector_centrality = nx.eigenvector_centrality(G, max_iter=1000)\n",
    "    \n",
    "    # 2. Community detection using Girvan-Newman algorithm\n",
    "    communities_generator = nx.community.girvan_newman(G.to_undirected())\n",
    "    top_level_communities = next(communities_generator)\n",
    "    community_dict = {node: i for i, community in enumerate(top_level_communities) for node in community}\n",
    "    \n",
    "    # 3. Influence score\n",
    "    pagerank = nx.pagerank(G)\n",
    "    \n",
    "    # Add these features to the DataFrame\n",
    "    email_network_df['degree_centrality'] = email_network_df.index.map(lambda x: degree_centrality.get(x, 0))\n",
    "    email_network_df['betweenness_centrality'] = email_network_df.index.map(lambda x: betweenness_centrality.get(x, 0))\n",
    "    email_network_df['eigenvector_centrality'] = email_network_df.index.map(lambda x: eigenvector_centrality.get(x, 0))\n",
    "    email_network_df['community'] = email_network_df.index.map(lambda x: community_dict.get(x, -1))\n",
    "    email_network_df['influence_score'] = email_network_df.index.map(lambda x: pagerank.get(x, 0))\n",
    "    \n",
    "    return email_network_df\n",
    "\n",
    "def calculate_email_interaction_counts(email_network_df):\n",
    "    def count_interactions(sent, received):\n",
    "        forwarded_count = 0\n",
    "        replied_count = 0\n",
    "        if isinstance(sent, pd.DataFrame) and 'Subject' in sent.columns:\n",
    "            forwarded_count = sent['Subject'].str.contains('Fwd:', case=False, na=False).sum()\n",
    "        if isinstance(received, pd.DataFrame) and 'Subject' in received.columns:\n",
    "            replied_count = received['Subject'].str.contains('Re:', case=False, na=False).sum()\n",
    "        return pd.Series({'forwarded_count': forwarded_count, 'replied_count': replied_count})\n",
    "\n",
    "    interaction_counts = email_network_df.apply(lambda row: count_interactions(row['sent'], row['received']), axis=1)\n",
    "    return pd.concat([email_network_df, interaction_counts], axis=1)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "def calculate_priority_urgency_features(email_network_df):\n",
    "    urgency_keywords = ['urgent', 'asap', 'immediately', 'critical', 'important']\n",
    "    importance_keywords = ['priority', 'crucial', 'vital', 'essential', 'key']\n",
    "    high_position_keywords = ['ceo', 'cfo', 'cto', 'president', 'director', 'manager', 'head']\n",
    "\n",
    "    def calculate_scores(sent, received):\n",
    "        if not isinstance(sent, pd.DataFrame) or not isinstance(received, pd.DataFrame):\n",
    "            return pd.Series({'urgency_score': 0, 'importance_score': 0})\n",
    "\n",
    "        all_emails = pd.concat([sent, received])\n",
    "        \n",
    "        # Urgency score\n",
    "        urgency_pattern = re.compile('|'.join(urgency_keywords), re.IGNORECASE)\n",
    "        urgency_count = all_emails['content'].apply(lambda x: len(urgency_pattern.findall(str(x)))).sum()\n",
    "        \n",
    "        avg_response_time = 24  # default to 24 hours if Date columns are not available\n",
    "        if 'Date' in sent.columns and 'Date' in received.columns:\n",
    "            # Convert to datetime and ensure UTC\n",
    "            sent_dates = pd.to_datetime(sent['Date'], utc=True)\n",
    "            received_dates = pd.to_datetime(received['Date'], utc=True)\n",
    "            \n",
    "            # Calculate time differences\n",
    "            time_diffs = []\n",
    "            for rec_date in received_dates:\n",
    "                responses = sent_dates[sent_dates > rec_date]\n",
    "                if not responses.empty:\n",
    "                    time_diffs.append((responses.iloc[0] - rec_date).total_seconds() / 3600)\n",
    "            \n",
    "            avg_response_time = np.mean(time_diffs) if time_diffs else 24\n",
    "        \n",
    "        urgency_score = urgency_count / (1 + avg_response_time)  # Normalize by response time\n",
    "\n",
    "        # Importance score\n",
    "        importance_pattern = re.compile('|'.join(importance_keywords), re.IGNORECASE)\n",
    "        importance_count = all_emails['content'].apply(lambda x: len(importance_pattern.findall(str(x)))).sum()\n",
    "        \n",
    "        position_pattern = re.compile('|'.join(high_position_keywords), re.IGNORECASE)\n",
    "        sender_position_score = all_emails['From'].apply(lambda x: len(position_pattern.findall(str(x)))).sum()\n",
    "        \n",
    "        importance_score = importance_count + sender_position_score\n",
    "\n",
    "        return pd.Series({'urgency_score': urgency_score, 'importance_score': importance_score})\n",
    "\n",
    "    scores = email_network_df.apply(lambda row: calculate_scores(row['sent'], row['received']), axis=1)\n",
    "    email_network_df = pd.concat([email_network_df, scores], axis=1)\n",
    "    return email_network_df\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def calculate_collaboration_metrics(email_network_df):\n",
    "    def extract_department(email):\n",
    "        return email.split('@')[0].split('.')[-1] if isinstance(email, str) else ''\n",
    "\n",
    "    def calculate_metrics(sent, received):\n",
    "        if not isinstance(sent, pd.DataFrame) or not isinstance(received, pd.DataFrame):\n",
    "            return pd.Series({'cross_dept_comm_freq': 0, 'project_cluster': -1})\n",
    "\n",
    "        all_emails = pd.concat([sent, received])\n",
    "        \n",
    "        # Cross-department communication frequency\n",
    "        all_emails['sender_dept'] = all_emails['From'].apply(extract_department)\n",
    "        all_emails['receiver_dept'] = all_emails['To'].apply(extract_department)\n",
    "        cross_dept_comm = (all_emails['sender_dept'] != all_emails['receiver_dept']).sum()\n",
    "        cross_dept_comm_freq = cross_dept_comm / len(all_emails) if len(all_emails) > 0 else 0\n",
    "\n",
    "        # Project-based communication clusters\n",
    "        vectorizer = TfidfVectorizer(max_features=100, stop_words='english')\n",
    "        tfidf_matrix = vectorizer.fit_transform(all_emails['content'].astype(str))\n",
    "        \n",
    "        # Adjust number of clusters based on data size\n",
    "        n_clusters = min(max(1, tfidf_matrix.shape[0] // 10), 5)  # At least 1, at most 5 clusters\n",
    "        \n",
    "        if n_clusters > 1:\n",
    "            kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "            cluster = kmeans.fit_predict(tfidf_matrix)[0]\n",
    "        else:\n",
    "            cluster = 0\n",
    "\n",
    "        return pd.Series({'cross_dept_comm_freq': cross_dept_comm_freq, 'project_cluster': cluster})\n",
    "\n",
    "    metrics = email_network_df.apply(lambda row: calculate_metrics(row['sent'], row['received']), axis=1)\n",
    "    return pd.concat([email_network_df, metrics], axis=1)\n",
    "\n",
    "def process_email_network(email_network_df):\n",
    "    # Ensure index is unique\n",
    "    email_network_df = email_network_df.reset_index(drop=True)\n",
    "    \n",
    "    # Calculate email interaction counts\n",
    "    email_network_df = calculate_email_interaction_counts(email_network_df)\n",
    "\n",
    "    # Calculate network features\n",
    "    email_network_df = calculate_network_features(email_network_df)\n",
    "\n",
    "    # Calculate priority and urgency features\n",
    "    email_network_df = calculate_priority_urgency_features(email_network_df)\n",
    "\n",
    "    # Calculate collaboration metrics\n",
    "    email_network_df = calculate_collaboration_metrics(email_network_df)\n",
    "\n",
    "    # Ensure all relevant columns are numeric\n",
    "    numeric_columns = ['influence_score', 'forwarded_count', 'replied_count']\n",
    "    for col in numeric_columns:\n",
    "        if col in email_network_df.columns:\n",
    "            email_network_df[col] = pd.to_numeric(email_network_df[col], errors='coerce').fillna(0)\n",
    "\n",
    "    # Adjust influence score based on forwarded and replied counts\n",
    "    if all(col in email_network_df.columns for col in numeric_columns):\n",
    "        email_network_df['adjusted_influence_score'] = email_network_df['influence_score'] * (1 + email_network_df['forwarded_count'] + email_network_df['replied_count'])\n",
    "    else:\n",
    "        print(\"Warning: Not all required columns present for adjusted_influence_score calculation\")\n",
    "        email_network_df['adjusted_influence_score'] = email_network_df['influence_score']\n",
    "\n",
    "    return email_network_df\n",
    "\n",
    "# Assuming email_network_df is your input DataFrame\n",
    "try:\n",
    "    email_network_df = process_email_network(email_network_df)\n",
    "    print(\"Processing completed successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {str(e)}\")\n",
    "    print(\"DataFrame info:\")\n",
    "    print(email_network_df.info())\n",
    "    print(\"\\nDataFrame head:\")\n",
    "    print(email_network_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_network_df.to_csv('email_network_df_original.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "person\n",
       "dutch.quigley@enron.com                           Date                         From  \\\n",
       "0 2001-11-05 08:48:47-08:00  veronica.espinoza@enron.com   \n",
       "\n",
       "                     To                             Subject  \\\n",
       "0  k..ratnala@enron.com  Credit Watch List--Week of 11/5/01   \n",
       "\n",
       "                    X-FileName  \\\n",
       "0  GNEMEC (Non-Privileged).pst   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                   content  \\\n",
       "0  To add additional people to this distribution, or if this report has been sent to you in error, please contact Veronica Espinoza at x6-6002. If there are any personnel in your group that were not included in this distribution, please insure that they receive a copy of this report. Attached is a revised Credit Watch listing for the week of 11/05/01. For other questions, please contact Jason R. There are no updates from last week's list.   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                tfidf_vector  \n",
       "0  [0.0, 0.0, 0.11076183030737578, 0.0, 0.0, 0.0, 0.11582547486682462, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10546876001425726, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]  \n",
       "Name: received, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "display(email_network_df.received.iloc[[49]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating LLM query prompts using 10 processes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating prompts: 100%|██████████| 1285/1285 [09:22<00:00,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample of personalized LLM query prompts:\n",
      "\n",
      "User: harry's.group@enron.com\n",
      "Recommended LLM Query Prompts:\n",
      "1. 1. \"What are the critical details regarding Duke Energy's $7 million contribution to marine life mitigation that I should include in my upcoming report on the Moss Landing project?\"\n",
      "2. 2. \"Extract and summarize the recommendations made by the Moss Landing Siting Committee regarding the proposed construction of the Moss Landing plant.\"\n",
      "3. 3. \"Identify any follow-up actions or decisions that need to be made concerning the increase in generating capacity for the Moss Landing plant as discussed in recent emails.\"\n",
      "4. 4. \"Can you help me track the timeline for the approval process of the Moss Landing Power Project based on the latest communications about it?\"\n",
      "5. 5. \"What were the key points discussed in my emails concerning the environmental impacts of the Moss Landing plant operations on marine biology?\"\n",
      "6. 6. \"Summarize my interactions related to the California Energy Commission's licensing recommendations for the Moss Landing Power Project.\"\n",
      "7. 7. \"What specific information do I need to communicate to stakeholders about the $500 million Moss Landing Power Plant Project based on my recent email exchanges?\"\n",
      "8. 8. \"List any additional considerations or concerns raised about the Moss Landing plant's construction and operation from the recent siting committee discussions.\"\n",
      "9. 9. \"Analyze my recent emails for any potential questions or feedback I should prepare regarding the marine biology mitigation associated with Duke Energy's operations.\"\n",
      "10. 10. \"Recognize any trends in the tone and sentiment of my discussions about the Moss Landing plant, especially related to marine life and community impact.\"\n",
      "\n",
      "User: meredith.eggleston@enron.com\n",
      "Recommended LLM Query Prompts:\n",
      "1. 1. \"Summarize the action items from my recent email thread with Robert Hertzberg regarding the legislation for energy-efficient power plants.\"\n",
      "2. \n",
      "3. 2. \"What key insights can I extract from my discussion with Burton about the proposed $150 million funding initiative for renewable energy supply?\"\n",
      "4. \n",
      "5. 3. \"List the follow-up actions required from my emails related to city regulations on power plant capacities sent to Davis over the past month.\"\n",
      "6. \n",
      "7. 4. \"Analyze my email correspondence with Robert Hertzberg about the Mobile Efficiency Brigade project and highlight any important deadlines or commitments I need to address.\"\n",
      "8. \n",
      "9. 5. \"What major concerns did I express in my emails discussing the $14 billion debt issue faced by PG&E and Southern California Edison with my contacts?\"\n",
      "10. \n",
      "11. 6. \"Provide a summary of the funding options discussed in my emails related to grants and loans for schools and local governments for energy conservation.\"\n",
      "12. \n",
      "13. 7. \"Identify any urgent tasks I need to address based on my recent email exchanges about the establishment of purchasing agreements for new power plants.\"\n",
      "14. \n",
      "15. 8. \"Review my emails over the last three months and summarize sentiment and concerns regarding the energy crisis as discussed with Davis and Burton.\"\n",
      "16. \n",
      "17. 9. \"Extract the main points from my communication with Robert Hertzberg about the strategic planning for energy conservation programs.\"\n",
      "18. \n",
      "19. 10. \"What are the critical pieces of legislation discussed in my emails with Burton, and what actions are required from my end regarding these bills?\"\n",
      "\n",
      "User: simone.la@enron.com\n",
      "Recommended LLM Query Prompts:\n",
      "1. 1. \"Can you summarize the key points and any action items from my email exchanges with Adam Johnson specifically regarding EnronOnline communications?\"\n",
      "2. 2. \"What are the main contact details I’ve confirmed in my email discussions with Adam Johnson, including any updates on his phone number?\"\n",
      "3. 3. \"Analyze the sentiment of my recent emails to and from Adam Johnson and provide insights on whether the tone has shifted in any particular thread involving EnronOnline.\"\n",
      "4. 4. \"Identify any follow-up tasks or unresolved questions from my email conversations regarding Enron and Adam Johnson over the past month.\"\n",
      "5. 5. \"Please extract and list the most frequently mentioned topics in my emails with Adam Johnson, focusing on any trends related to EnronOnline.\"\n",
      "6. 6. \"What specific information about EnronOnline have I communicated to Adam Johnson that requires further clarification or follow-up?\"\n",
      "7. 7. \"Can you provide a summary of all emails sent to Adam Johnson that include a discussion on contact information or phone numbers?\"\n",
      "8. 8. \"Examine my email correspondence with Adam Johnson for any instances of urgent matters regarding EnronOnline, even if they are categorized as informational.\"\n",
      "9. 9. \"Please identify patterns in my work-related communication frequency with Adam Johnson and summarize any consistent themes that arise in our discussions.\"\n",
      "10. 10. \"List any recommendations or suggestions I’ve received from Adam Johnson in our email discussions that could enhance our collaboration on EnronOnline projects.\"\n",
      "\n",
      "User: kenny.nicoll@enron.com\n",
      "Recommended LLM Query Prompts:\n",
      "1. 1. \"What are the specific dates I removed from the business calendar regarding Memorial Day and New Year's Day, and how do these changes affect our operations for ERMS/TAGG Production up to 2025?\"\n",
      "2. \n",
      "3. 2. \"Can you summarize the main points discussed concerning the adjustment of the business holiday calendar from my email exchanges with Truong Vu?\"\n",
      "4. \n",
      "5. 3. \"Please outline any notable patterns or trends related to the removal of business days in my correspondence, especially with regards to notable holidays mentioned in my emails.\"\n",
      "6. \n",
      "7. 4. \"What was the rationale provided by me in my emails for removing Memorial Day as a business day, and how was this decision communicated to my team?\"\n",
      "8. \n",
      "9. 5. \"List all the years from 2002 to 2025 where I have communicated changes to the business calendar for ERMS/TAGG Production, along with specific dates mentioned in these emails.\"\n",
      "10. \n",
      "11. 6. \"Analyze the sentiment of my email discussions regarding the holiday calendar adjustments and provide insights into how my communication with Truong Vu has evolved over this topic.\"\n",
      "12. \n",
      "13. 7. \"Identify any recurring themes or key phrases in my emails about business day removals, specifically focusing on the conversations that include Truong Vu.\"\n",
      "14. \n",
      "15. 8. \"What steps should I take next to ensure proper communication of the updated holiday calendar changes to my team, based on my previous discussions?\"\n",
      "16. \n",
      "17. 9. \"Summarize the implications of eliminating New Year's Day as a business day for our operations based on the email exchanges I've had regarding this topic.\"\n",
      "18. \n",
      "19. 10. \"Can you extract any follow-up tasks I might need to address regarding the holiday calendar changes that I've discussed with Truong Vu?\"\n",
      "\n",
      "User: jay.zoellner@enron.com\n",
      "Recommended LLM Query Prompts:\n",
      "1. 1. \"Summarize the key trade-offs discussed with Burton and Bob Hertzberg regarding MOU alternatives, particularly focusing on their proposals for writing off Edison creditors' debts.\"\n",
      "2. 2. \"What specific action items do I need to follow up on from my email exchanges with Steve Maviglio about the bankruptcy of PG&E and its implications for our ongoing discussions?\"\n",
      "3. 3. \"Extract the main arguments presented in my conversations about the debt write-off proposals and how they align with the interests of Edison creditors.\"\n",
      "4. 4. \"Can you analyze the sentiment of my recent emails concerning power supply deals, paying special attention to any expressions of frustration I mentioned regarding negotiations?\"\n",
      "5. 5. \"Compile a list of priorities from my recent discussions with Bob Hertzberg related to the complications surrounding the Edison debt crisis and the proposed MOU changes.\"\n",
      "6. 6. \"What were the critical points made by Burton in our emails about the financial solutions for PG&E's bankruptcy, and how can I address his concerns in future communications?\"\n",
      "7. 7. \"Identify any unresolved questions in my email correspondence about the $14 billion in debts accumulated by PG&E and Southern California Edison that may require my attention.\"\n",
      "8. 8. \"Summarize the implications discussed in my recent emails regarding the shifting dynamics of power consumers shouldering the utility debts, specifically mentioning Burton and Maviglio’s views.\"\n",
      "9. 9. \"What were the main concerns raised by the stakeholders involved in the discussions about the Edison and PG&E debt issues that I need to integrate into my ongoing strategy?\"\n",
      "10. 10. \"Evaluate the urgency and importance of follow-ups required from my recent communications about bankruptcy negotiations with PG&E, highlighting any actions I must prioritize.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from email_analysis_utils import parallel_generate_llm_query_prompts\n",
    "\n",
    "\n",
    "# Generate prompt recommendations for each user\n",
    "email_network_df_prompts = parallel_generate_llm_query_prompts(email_network_df, num_processes=os.cpu_count())\n",
    "\n",
    "# Display a sample of the recommendations\n",
    "print(\"\\nSample of personalized LLM query prompts:\")\n",
    "sample_users = email_network_df.sample(5)\n",
    "for _, user in sample_users.iterrows():\n",
    "    print(f\"\\nUser: {user.name}\")\n",
    "    print(\"Recommended LLM Query Prompts:\")\n",
    "    for i, prompt in enumerate(user['recommended_llm_queries'], 1):\n",
    "        print(f\"{i}. {prompt}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tutorials",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
